# Multimodal Idiomaticity Representation

This repository contains a Jupyter notebook that explores methods for representing and predicting idiomatic expressions using multimodal models (OpenAI CLIP + PyTorch). The notebook walks through:

1. **Library & Data Import**  
2. **NLP Exploratory Data Analysis** on text examples  
3. **Zero-Shot Prediction** with CLIP  
4. **LLM-Based Data Augmentation** to address class imbalance  
5. **Fine-Tuning CLIP** on your idiomatic dataset  
6. **Visualizing Predictions** on custom images and test data  
